\UseRawInputEncoding
\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language

% \usepackage[deutsch]{babel}
\usepackage[ngerman]{babel}

%\usepackage[ansinew]{inputenc}
\usepackage[utf8]{inputenc}

% nice code input for appendix
\usepackage{tcolorbox}
\tcbuselibrary{minted,breakable,xparse,skins}

% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=2cm,marginparwidth=1.75cm]{geometry}
\usepackage[utf8]{inputenc}
% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=black]{hyperref}
% for pictures ... reason: https://tex.stackexchange.com/questions/8625/force-figure-placement-in-text
\usepackage{float}

% highlighted code in text
\usepackage{soul}
\definecolor{Light}{gray}{.90}
\sethlcolor{Light}
\let\OldTexttt\texttt
\renewcommand{\texttt}[1]{\OldTexttt{\hl{#1}}}

% einrücken abschalten
\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
		\begin{center}
			\vspace*{1cm}
			
			\Huge
			\textbf{Spark \\Type-Token-Ratio}
			
			\vspace{2cm}
			
			\Large
                Programmierkonzepte und Algorithmen WS25/26\\
				Justin Gebert, Ole Lordieck\\
   
			\vfill
			
			\vspace{0.8cm}
			
			\includegraphics[width=0.3\textwidth]{images/htw_logo.jpg} 
			
			\vspace{1cm}
			
			Hochschule für Technik und Wirtschaft Berlin\\
			Fachbereich 4\\
			Informatik, Kommunikation und Wirtschaft
			
			
		\end{center}
	\end{titlepage}

\newpage

\tableofcontents
\thispagestyle{empty}  % no page number

\newpage

%------------------------------------------------------------------------------
% START CONTENT
%
%\setcounter{page}{1}  % start counting pages after table of contents

\section{Aufgabenstellung}

Die Aufgabe besteht darin, gegebene Textdaten mithilfe von Spark verteilt zu verarbeiten, um die sprachliche Vielfalt der enthaltenen Texte zu untersuchen. Dazu sollen die Texte zunächst als normale Textdateien eingelesen. Anschließend soll mit Spark die Type-Token-Ratio (TTR) für jede im Datensatz vorkommende Sprache berechnet werden. Die TTR wird mit der Anzahl der einzigartigen Wörter durch die Gesamtzahl aller Wörter berechnet. 
\[
\text{TTR} = \frac{\text{Anzahl einzigartiger Wörter}}{\text{Anzahl aller Wörter}}
\]
Außerdem sollen vor der Analyse alle Stoppwörter entfernt werden, um aussagekräftigere Ergebnisse zu erhalten. Ziel ist es, die sprachliche Vielfalt zwischen den Sprachen zu vergleichen und gleichzeitig die Vorteile verteilter Big-Data-Verarbeitung sichtbar zu machen, indem der Datensatz bei Bedarf künstlich vergrößert wird.

\subsection{Ausführen der Lösung}
Der Job muss zunächst gebaut werden:
\begin{verbatim}
mvn clean package
\end{verbatim}

Anschließend wird er mit \texttt{spark-submit} gestartet. Die Anzahl der Kerne kann über den Master-Parameter konfiguriert werden.

\textbf{Befehl für 4 Kerne:}
\begin{verbatim}
spark-submit --class TTRJob --master "local[4]" \
    target/prog-alg-1.0.jar data/text data/stopwords results
\end{verbatim}

\textbf{Automatisierte Benchmarks:}
Für die Leistungsmessung gibt es ein Python-Script (\texttt{scripts/run\_benchmarks.py}), das den Job mit 1, 2, 4 und 8 Kernen ausführt und die Laufzeiten protokolliert.

\textit{Eine detaillierte Anleitung zur Reproduktion der Benchmarks befindet sich in der \texttt{README.md} Datei.}

\section{Lösungsbeschreibung}


\subsection{Datenannahmen und Einlesen}
\begin{itemize}
    \item Eingang: Textdateien im Verzeichnis \texttt{data/text}
    \item Sprache wird aus dem Dateipfad mit einer Regex extrahiert (Parent-Ordner = Sprachcode)
    \item Einlesen mit \texttt{wholeTextFiles}: liefert Paare \texttt{(Pfad, Inhalt)} für Text und Sprachzuordnung
\end{itemize}

\subsection{Preprocessing}
\begin{itemize}
    \item Extraktion von W\"ortern (\texttt{\textbackslash p\{L\}+}), um auch nicht-lateinische Sprachen unterstützt werden
    \item Normalisierung und Kleinschreibung zur Reduktion von Duplikaten
    \item Stoppwort-Filter
\end{itemize}

\subsection{Verteilte Berechnung in Spark}
\begin{itemize}
    \item Erzeugung eines RDD mit Paaren \texttt{(language, word)}
    \item \textbf{Gesamtzahl Tokens}: \texttt{mapToPair((lang,1))} + \texttt{reduceByKey(sum)}
    \item \textbf{Einzigartige Tokens}: \texttt{distinct()} auf \texttt{(lang,word)} + \texttt{reduceByKey}
    \item Join der beiden Ergebnisse pro Sprache und Berechnung von \texttt{ttr = unique/total}
\end{itemize}

\subsection{Speicherung der Ergebnisse}
\begin{itemize}
    \item Ausgabe als \textbf{CSV}
    \item Ausgabe auf Konsole zur schnellen Überprüfung
    \item Zeit messungen in der Konsole
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{images/flow_diagram.png}
    \caption{Flow Diagramm des Spark Jobs}
\end{figure}


\section{Beschreibung des Codes}

Der Code befindet sich in der Klasse \texttt{TTRJob.java}. Im Folgenden werden die wichtigsten Code-Fragmente erläutert.

\subsection{Einlesen der Dateien}
Die Textdateien werden mit \texttt{wholeTextFiles} eingelesen, um den Pfad für die Sprachextraktion zu erhalten:
\begin{verbatim}
JavaPairRDD<String, String> filesRDD = sc.wholeTextFiles(textDir + "/*/*.txt", 8);
\end{verbatim}

\subsection{Tokenisierung und Stoppwort-Filter}
Für die Tokenisierung wird ein Unicode-Pattern verwendet (\texttt{\textbackslash p\{L\}+}), das alle Unicode-Buchstaben erkennt. Die Stoppwörter werden per Broadcast verteilt:
\begin{verbatim}
Broadcast<Map<String, Set<String>>> broadcastStopwords = 
    sc.broadcast(stopwordsMap);

Matcher matcher = WORD_PATTERN.matcher(content);
while (matcher.find()) {
    String word = normalizeWord(matcher.group());
    if (!stopwords.contains(word)) {
        pairs.add(new Tuple2<>(language, word));
    }
}
\end{verbatim}

\subsection{TTR-Berechnung}
Die verteilte Berechnung erfolgt in zwei Schritten mit anschließendem Join:
\begin{verbatim}
// Total tokens per language
JavaPairRDD<String, Long> totalTokensPerLang = langWordPairs
    .mapToPair(t -> new Tuple2<>(t._1(), 1L))
    .reduceByKey(Long::sum);

// Unique tokens per language
JavaPairRDD<String, Long> uniqueTokensPerLang = langWordPairs
    .distinct()
    .mapToPair(t -> new Tuple2<>(t._1(), 1L))
    .reduceByKey(Long::sum);

// Join and calculate TTR
JavaPairRDD<String, Tuple2<Long, Long>> joinedCounts = 
    totalTokensPerLang.join(uniqueTokensPerLang);
double ttr = (double) unique / total;
\end{verbatim}

\section{Ergebnisse}

Die folgende Tabelle zeigt die Ergebnisse der TTR-Berechnung für alle acht Sprachen im Datensatz (134 MB, 363 Dateien):

\begin{table}[H]
\centering
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Sprache} & \textbf{Total Tokens} & \textbf{Unique Tokens} & \textbf{TTR} \\
\hline
dutch     &  60.739    &  12.222   & 0,2012 \\
english   & 1.984.198  &  69.223   & 0,0349 \\
french    & 2.305.570  &  78.002   & 0,0338 \\
german    & 2.174.079  & 157.107   & 0,0723 \\
italian   & 1.454.801  &  98.773   & 0,0679 \\
russian   &   201.710  &  59.296   & 0,2940 \\
spanish   &   622.341  &  66.591   & 0,1070 \\
ukrainian &   473.116  &  94.795   & 0,2004 \\
\hline
\end{tabular}
\caption{TTR-Ergebnisse pro Sprache}
\end{table}

Russisch zeigt die höchste sprachliche Vielfalt (TTR = 0,29). Französisch und Englisch haben niedrigere TTR-Werte (ca. 0,03).

\section{Tests von Leistung und Laufzeiten}

\subsection{Messaufbau}
\begin{itemize}
    \item \textbf{Hardware}: MacBook mit Apple Silicon, 18GB RAM, Spark Local Mode
    \item \textbf{Datensatz}: Original (134 MB, 363 Dateien), vergrößert (672 MB, 1815 Dateien) und huge (2,6 GB, 6045 Dateien)
    \item \textbf{Baseline}: Serielle Implementierung
    \item \textbf{Parallelisierung}: Tests mit 1, 2, 4 und 8 Kernen
\end{itemize}

\subsection{Ergebnisse und Analyse}

Die Performance-Tests wurden auf drei Datensätzen durchgeführt, um das Verhalten bei unterschiedlichen Datenmengen zu untersuchen:
\begin{enumerate}
    \item \textbf{Small} (134 MB)
    \item \textbf{Medium} (672 MB)
    \item \textbf{Huge} (2,6 GB)
\end{enumerate}

\subsubsection{Laufzeit-Vergleich: Serial vs. Spark}
Die folgende Grafik zeigt den Vergleich zwischen der seriellen Java-Implementierung und Spark (mit verschiedenen Kern-Anzahlen).

\begin{figure}[H]
    \centering
    \includegraphics[width=1.0\linewidth]{images/benchmark_comparison.png}
    \caption{Laufzeitvergleich über verschiedene Datensatzgrößen}
\end{figure}

\begin{table}[H]
\centering
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Ausführung} & \textbf{Small (134 MB)} & \textbf{Medium (672 MB)} & \textbf{Huge (2,6 GB)} \\
\hline
Serial (Java) & \textbf{1,99 s} & \textbf{9,25 s} & 42,47 s \\
Spark (1 Core) & 8,31 s & 34,40 s & 146,85 s \\
Spark (8 Cores) & 3,12 s & 14,58 s & \textbf{32,36 s} \\
\hline
\end{tabular}
\caption{Kern-Ergebnisse der Benchmarks}
\end{table}

\textbf{Beobachtung:}
\begin{itemize}
    \item \textbf{Small/Medium Data}: Hier dominiert die \textbf{Serial}-Implementierung. Der Overhead von Spark ist im Verhältnis zur Rechenzeit zu hoch.
    \item \textbf{Big Data (2,6 GB)}: Hier zeigt sich der \textbf{Wendepunkt}. Spark (8 Cores) überholt die serielle Lösung (32s vs 42s). Die Parallelisierung zahlt sich nun aus, da die reine Rechenlast den Verwaltungs-Overhead übersteigt.
\end{itemize}

\subsubsection{Skalierbarkeit (Speedup)}
Die Speedup-Analyse zeigt, wie effizient Spark zusätzliche Kerne nutzt (Referenz: Spark 1 Core).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{images/speedup_comparison.png}
    \caption{Skalierung (Speedup) relativ zu Spark 1-Core}
\end{figure}

\textbf{Fazit:}
Spark zeigt auf dem größtem Datensatz einen Speedup von ca. \textbf{4,5x} auf 8 Kernen. Dies bestätigt, dass Spark für größere Datenmengen skaliert, während die serielle Lösung linear an die Hardware-Grenzen gebunden ist.



\section{Fazit}

\begin{itemize}
    \item Die Type-Token-Ratio konnte erfolgreich für acht Sprachen mit Apache Spark berechnet werden.
    \item \textbf{Höchste sprachliche Vielfalt}: Russisch (TTR = 0,29).
    \item \textbf{Niedrigste Vielfalt}: Französisch und Englisch (TTR = 0,03).
    \item Die Parallelisierung zeigt mit 8 Kernen einen Speedup von \textbf{4,5x} gegenüber sequentieller Verarbeitung auf dem 2,6 GB Datensatz.
    \item Der Broadcast der Stoppwörter und das Caching der RDDs optimieren die Performance.
    \item Der \texttt{distinct()}-Operator ist die rechenintensivste Operation (Shuffle).
\end{itemize}

\newpage

\clearpage
\appendix

\end{document}
