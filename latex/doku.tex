\UseRawInputEncoding
\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language

% \usepackage[deutsch]{babel}
\usepackage[ngerman]{babel}

%\usepackage[ansinew]{inputenc}
\usepackage[utf8]{inputenc}

% nice code input for appendix
\usepackage{tcolorbox}
\tcbuselibrary{minted,breakable,xparse,skins}

% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=2cm,marginparwidth=1.75cm]{geometry}
\usepackage[utf8]{inputenc}
% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=black]{hyperref}
% for pictures ... reason: https://tex.stackexchange.com/questions/8625/force-figure-placement-in-text
\usepackage{float}

% highlighted code in text
\usepackage{soul}
\definecolor{Light}{gray}{.90}
\sethlcolor{Light}
\let\OldTexttt\texttt
\renewcommand{\texttt}[1]{\OldTexttt{\hl{#1}}}

% einrücken abschalten
\setlength{\parindent}{0pt}

\begin{document}

\begin{titlepage}
		\begin{center}
			\vspace*{1cm}
			
			\Huge
			\textbf{Spark \\Type-Token-Ratio}
			
			\vspace{2cm}
			
			\Large
                Programmierkonzepte und Algorithmen WS25/26\\
				Justin Gebert, Ole Lordieck\\
   
			\vfill
			
			\vspace{0.8cm}
			
			\includegraphics[width=0.3\textwidth]{images/htw_logo.jpg} 
			
			\vspace{1cm}
			
			Hochschule für Technik und Wirtschaft Berlin\\
			Fachbereich 4\\
			Informatik, Kommunikation und Wirtschaft
			
			
		\end{center}
	\end{titlepage}

\newpage

\tableofcontents
\thispagestyle{empty}  % no page number

\newpage

%------------------------------------------------------------------------------
% START CONTENT
%
%\setcounter{page}{1}  % start counting pages after table of contents

\section{Aufgabenstellung}

Die Aufgabe besteht darin, einen gegebenen Textkorpus mithilfe von Apache Spark verteilt zu verarbeiten, um die sprachliche Vielfalt der enthaltenen Texte zu untersuchen. Dazu sollen die Texte zunächst als normale Textdateien eingelesen. Anschließend soll mit Spark die Type-Token-Ratio (TTR) für jede im Datensatz vorkommende Sprache berechnet werden. Die TTR wird mit der Anzahl der einzigartigen Wörter durch die Gesamtzahl aller Wörter berechnet. 
\[
\text{TTR} = \frac{\text{Anzahl einzigartiger Wörter}}{\text{Anzahl aller Wörter}}
\]
Außerdem sollen vor der Analyse alle Stoppwörter entfernt werden, um aussagekräftigere Ergebnisse zu erhalten. Ziel ist es, die sprachliche Vielfalt zwischen den Sprachen zu vergleichen und gleichzeitig die Vorteile verteilter Big-Data-Verarbeitung sichtbar zu machen, indem der Datensatz bei Bedarf künstlich vergrößert wird.

\subsection{Ausführung des Spark Jobs}
Der Job muss zunächst gebaut werden:
\begin{verbatim}
mvn clean package
\end{verbatim}

Anschließend wird er mit \texttt{spark-submit} gestartet. Die Anzahl der Kerne kann dabei flexibel über den Master-Parameter konfiguriert werden.

\textbf{Befehl für 4 Kerne:}
\begin{verbatim}
spark-submit --class TTRJob --master "local[4]" \
    target/prog-alg-1.0.jar data/text data/stopwords results
\end{verbatim}

\textbf{Automatisierte Benchmarks:}
Für die Leistungsmessung wurde ein Python-Script (\texttt{scripts/run\_benchmarks.py}) entwickelt, das den Job automatisch mit 1, 2, 4 und 8 Kernen ausführt und die Laufzeiten protokolliert.

\section{Lösungsbeschreibung}


\subsection{Datenannahmen und Einlesen}
\begin{itemize}
    \item Eingang: Textdateien in einem Verzeichnis (empfohlen: \texttt{data/raw/<lang>/*.txt})
    \item Sprache wird aus dem Dateipfad mit einer Regex extrahiert (Standard: Elternordner = Sprachcode)
    \item Einlesen mit \texttt{wholeTextFiles}: liefert Paare \texttt{(Pfad, Inhalt)} und erlaubt dadurch robuste Sprachzuordnung
\end{itemize}

\subsection{Preprocessing}
\begin{itemize}
    \item Unicode-Tokenisierung: Extraktion von Wortfolgen (\texttt{\textbackslash p\{L\}+}), damit auch nicht-lateinische Sprachen unterstützt werden
    \item Normalisierung und Kleinschreibung zur Reduktion von Duplikaten (z.B. verschiedene Unicode-Formen)
    \item Filter:
    \begin{itemize}
        \item minimale Token-Länge (\texttt{minLen})
        \item Stoppwort-Filter
    \end{itemize}
\end{itemize}

\subsection{Verteilte Berechnung in Spark}
\begin{itemize}
    \item Erzeugung eines RDD mit Paaren \texttt{(language, word)}
    \item \textbf{Gesamtzahl Tokens}: \texttt{mapToPair((lang,1))} + \texttt{reduceByKey(sum)}
    \item \textbf{Einzigartige Tokens}: zwei Modi
    \begin{itemize}
        \item \textbf{Exakt}: \texttt{distinct()} auf \texttt{(lang,word)} + \texttt{reduceByKey}
        \item \textbf{Approx. (optional)}: \texttt{countApproxDistinctByKey(relativeSD)} (schneller auf großen Datenmengen)
    \end{itemize}
    \item Join der beiden Ergebnisse pro Sprache und Berechnung von \texttt{ttr = unique/total}
\end{itemize}

\subsection{Speicherung der Ergebnisse}
\begin{itemize}
    \item Ausgabe als \textbf{CSV} (mit Header, Ergebnisse sortiert nach Sprache)
    \item Ausgabe auf Konsole zur schnellen Überprüfung
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{images/spark_flow_diagram.png}
    \caption{Datenfluss-Diagramm (DAG) des Spark Jobs}
\end{figure}


\section{Beschreibung des Codes}

Der Code befindet sich in der Klasse \texttt{TTRJob.java}. Im Folgenden werden die wichtigsten Code-Fragmente erläutert.

\subsection{Einlesen der Dateien}
Die Textdateien werden mit \texttt{wholeTextFiles} eingelesen, um den Pfad für die Sprachextraktion zu erhalten:
\begin{verbatim}
JavaPairRDD<String, String> filesRDD = sc.wholeTextFiles(textDir + "/*/*.txt", 8);
\end{verbatim}

\subsection{Tokenisierung und Stoppwort-Filter}
Für die Tokenisierung wird ein Unicode-Pattern verwendet (\texttt{\textbackslash p\{L\}+}), das alle Unicode-Buchstaben erkennt. Die Stoppwörter werden per Broadcast verteilt:
\begin{verbatim}
// Broadcast stopwords to all workers
Broadcast<Map<String, Set<String>>> broadcastStopwords = 
    sc.broadcast(stopwordsMap);

// Token extraction with filtering
Matcher matcher = WORD_PATTERN.matcher(content);
while (matcher.find()) {
    String word = normalizeWord(matcher.group());
    if (!stopwords.contains(word)) {
        pairs.add(new Tuple2<>(language, word));
    }
}
\end{verbatim}

\subsection{TTR-Berechnung}
Die verteilte Berechnung erfolgt in zwei Schritten mit anschließendem Join:
\begin{verbatim}
// Total tokens per language
JavaPairRDD<String, Long> totalTokensPerLang = langWordPairs
    .mapToPair(t -> new Tuple2<>(t._1(), 1L))
    .reduceByKey(Long::sum);

// Unique tokens per language
JavaPairRDD<String, Long> uniqueTokensPerLang = langWordPairs
    .distinct()
    .mapToPair(t -> new Tuple2<>(t._1(), 1L))
    .reduceByKey(Long::sum);

// Join and calculate TTR
JavaPairRDD<String, Tuple2<Long, Long>> joinedCounts = 
    totalTokensPerLang.join(uniqueTokensPerLang);
double ttr = (double) unique / total;
\end{verbatim}

\section{Screenshots der Ergebnisse}

Die folgende Tabelle zeigt die Ergebnisse der TTR-Berechnung für alle acht Sprachen im Datensatz (134 MB, 363 Dateien):

\begin{table}[H]
\centering
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Sprache} & \textbf{Total Tokens} & \textbf{Unique Tokens} & \textbf{TTR} \\
\hline
dutch     &  60.739    &  12.222   & 0,2012 \\
english   & 1.984.198  &  69.223   & 0,0349 \\
french    & 2.305.570  &  78.002   & 0,0338 \\
german    & 2.174.079  & 157.107   & 0,0723 \\
italian   & 1.454.801  &  98.773   & 0,0679 \\
russian   &   201.710  &  59.296   & 0,2940 \\
spanish   &   622.341  &  66.591   & 0,1070 \\
ukrainian &   473.116  &  94.795   & 0,2004 \\
\hline
\end{tabular}
\caption{TTR-Ergebnisse pro Sprache}
\end{table}

\textbf{Interpretation:} Russisch zeigt die höchste sprachliche Vielfalt (TTR = 0,29), was auf die reiche Morphologie zurückzuführen ist. Französisch und Englisch haben niedrigere TTR-Werte (ca. 0,03), was bei großen Textmengen typisch ist, da häufige Wörter wiederholt werden.

\section{Tests}

Zur Validierung der Ergebnisse wurden folgende Tests durchgeführt:

\subsection{Funktionale Tests}
\begin{itemize}
    \item \textbf{Stoppwort-Filter}: Für jede Sprache wurden die entsprechenden Stoppwort-Listen geladen (275--619 Wörter pro Sprache). Die Filter wurden korrekt angewandt.
    \item \textbf{Unicode-Unterstützung}: Russische und Ukrainische Texte mit kyrillischen Zeichen wurden korrekt tokenisiert.
    \item \textbf{Sprachextraktion}: Die Sprache wurde aus dem Dateipfad (\texttt{data/text/<sprache>/}) korrekt extrahiert.
\end{itemize}

\subsection{Ergebnis-Validierung}
\begin{itemize}
    \item Alle 8 Sprachen wurden erkannt und verarbeitet (363 Dateien)
    \item TTR-Werte liegen im erwarteten Bereich (0,03 -- 0,30)
    \item CSV-Ausgabe wurde erfolgreich generiert
\end{itemize}

\section{Leistung und Laufzeiten}

\subsection{Messaufbau}
\begin{itemize}
    \item \textbf{Hardware}: MacBook mit Apple Silicon, Spark Local Mode
    \item \textbf{Datensatz}: Original (134 MB, 363 Dateien) und vergrößert (672 MB, 1815 Dateien)
    \item \textbf{Parallelisierung}: Tests mit 1, 2, 4 und 8 Kernen
\end{itemize}

\subsection{Ergebnisse}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
\textbf{Kerne} & \textbf{Laufzeit (s)} & \textbf{Speedup} \\
\hline
1 & 57,30 & 1,0x \\
2 & 28,53 & 2,0x \\
4 & 16,31 & 3,5x \\
8 & 12,26 & 4,7x \\
\hline
\end{tabular}
\caption{Laufzeiten auf dem 672 MB Datensatz}
\end{table}

\textbf{Analyse}: Die Skalierung zeigt deutliche Vorteile der Parallelisierung. Durch die Optimierung auf Spark Core (ohne SQL-Overhead) konnte der Speedup von 3,2x auf 4,7x gesteigert werden. Die Laufzeit auf 8 Kernen sank auf ca. 12,3s. Der Speedup ist nicht perfekt linear, da:
\begin{itemize}
    \item Shuffle-Operationen (z.B. \texttt{distinct()}, \texttt{reduceByKey}) Synchronisation erfordern
    \item Der Local Mode alle Kerne auf einem Rechner nutzt (shared memory limit)
    \item Overhead durch Spark-Koordination
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{images/benchmark.png}
    \caption{Laufzeit und Speedup in Abhängigkeit der CPU-Kerne}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{images/ttr_comparison.png}
    \caption{Vergleich der sprachlichen Vielfalt (TTR) pro Sprache}
\end{figure}


\section{Fazit}

\begin{itemize}
    \item Die Type-Token-Ratio konnte erfolgreich für acht Sprachen mit Apache Spark berechnet werden.
    \item \textbf{Höchste sprachliche Vielfalt}: Russisch (TTR = 0,29).
    \item \textbf{Niedrigste Vielfalt}: Französisch und Englisch (TTR = 0,03).
    \item Die Parallelisierung zeigt mit 8 Kernen einen Speedup von 3,2x gegenüber sequentieller Verarbeitung.
    \item Der Broadcast der Stoppwörter und das Caching der RDDs optimieren die Performance.
    \item Der \texttt{distinct()}-Operator ist die rechenintensivste Operation (Shuffle).
\end{itemize}

\newpage



%------------------------------------------------------------------------------
% BIBLIOGRAPHY AND FIGURE LIST
%
%\bibliographystyle{ieeetr}
%\bibliography{sample}
%\listoffigures
%------------------------------------------------------------------------------

\clearpage
\appendix

%------------------------------------------------------------------------------
% EIDESSTATTLICHE ERKLÄRUNG
%
%\newpage
%
%\section*{Eidesstattliche Erklärung}
% Hiermit erkläre ich, dass ich die vorliegende Arbeit selbstständig und eigenhändig sowie ohne unerlaubte fremde Hilfe und ausschließlich %unter Verwendung der aufgeführten Quellen und Hilfsmittel angefertigt habe.\\
% 
% \noindent Die selbständige und eigenständige Anfertigung versichert an Eides statt:
%
% \vspace{3cm}
% % Text über den Linien
% \noindent\hspace{1,05cm} Berlin, 11. Juli 2023\hfill\includegraphics[width=115pt]{signature.jpg} \hspace{1cm}
% \vspace{-0,3cm} % Anpassen der Höhe des Ort, Datum und Unterschrift
% 
% % Linien
% \noindent\hspace{1cm} \rule{3.25cm}{0.5pt} \hfill \rule{4cm}{0.5pt} \hspace{1cm}
% \vspace{-0,1cm} % Anpassen der Höhe des Textes unter den Linien
% 
% % Text unter den Linien
% \noindent\hspace{1,85cm} Ort, Datum \hfill Unterschrift \hspace{2cm}
%
%------------------------------------------------------------------------------

\end{document}
